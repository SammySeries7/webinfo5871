<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title> INFO 5871 project </title>
	<link rel="stylesheet" type="text/css" media="screen" href="app.css">
</head>

<nav class="menu-bar">
	<h1 class="logo">Tittiwat<span>T.</span></h1>
	<ul>
		<li><a href="index.html">Home</a></li>
		<li><a href="#">About</a></li>
		<li><a href="#">Project <i class="fas fa-caret-down"></i></a>

			<div class="dropdown-menu">
				<ul>
					<!--<li><a href="#">Pricing</a></li>-->
					<!--<li><a href="#">Portfolio</a></li>-->
					<li>
						<a href="#">Module-1 <i class="fas fa-caret-right"></i></a>

						<div class="dropdown-menu-1">
							<ul>
								<li><a href="1_1.html">Introduction</a></li>
								<li><a href="1_2.html">Data</a></li>
							</ul>
						</div>
					</li>

					<li>
						<a href="#">Module-2 <i class="fas fa-caret-right"></i></a>

						<div class="dropdown-menu-1">
							<ul>
								<li><a href="1_1.html">Updated Introduction</a></li>
								<li><a href="2_2.html">Clustering</a></li>
								<li><a href="2_3.html">ARM</a></li>
								<li><a href="2_4.html">LDA</a></li>
							</ul>
						</div>
					</li>

					<li>
						<a href="#">Module-3 <i class="fas fa-caret-right"></i></a>

						<div class="dropdown-menu-1">
							<ul>
								<li><a href="1_1.html">Updated Introduction#2</a></li>
								<li><a href="3_2.html">Naive Bayes</a></li>
								<li><a href="3_3.html">Decision Tree</a></li>
								<li><a href="3_4.html">SVM</a></li>
							</ul>
						</div>
					</li>

					<li>
						<a href="#">Module-4 <i class="fas fa-caret-right"></i></a>

						<div class="dropdown-menu-1">
							<ul>
								<li><a href="1_1.html">Updated Introduction_final</a></li>
								<li><a href="4_1.html">Neural Network</a></li>
								<li><a href="#">Module-3</a></li>
								<li><a href="#">Module-4</a></li>
							</ul>
						</div>
					</li>

					<li><a href="#">FAQ</a></li>
				</ul>
			</div>
		</li>
		<li><a href="#">Blog</a>
		</li>
		<li><a href="#">Contact us</a></li>
	</ul>
</nav>

<br>

<body>

	<main id="main">
		<h1> Support Vector Machines (SVM) </h1>
		<br>
		
		<section id="pt1" class="card">
			<div class="arial">
				<h3>What Support Vector Machines is and how to use it to gain information</h3>
				<br>
				<p>
					SVM stands for Support Vector Machines, which is a popular supervised machine learning algorithm used for classification and regression tasks.
				</p>
				<br>
				<p>
					In SVM, the goal is to find a hyperplane in a high-dimensional space that best separates the data points into different classes. The hyperplane is chosen such that it maximizes the margin, i.e., the distance between the hyperplane and the closest data points from each class.
				</p>
				<br>

				
				<p>
					SVM is effective in handling complex datasets with a large number of features and can handle both linear and nonlinear classification problems by using different types of kernel functions. Some common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid.
				</p>
				<br>
				
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/svm_intro.png">
				<div class="caption">The dataset</div>
				</div>
				<br>
				
				<p>
				SVM is effective in handling complex datasets with a large number of features and can handle both linear and nonlinear classification problems by using different types of kernel functions. Some common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid
				</p>
				<br>
				<p>
				SVM is a popular machine learning algorithm for text classification tasks because it is effective in handling high-dimensional feature spaces with sparse data. In text classification, the goal is to assign predefined categories or labels to documents based on their content. In this chapter, SVM is implemented to classify two different sets of labels. Several kernels will be applied with the dataset to find the most suitable one. The different cost value will be performed to understand the difference in the model accuracy. The result from the best model will be compared with the other methods such as decision trees and Naive Bayes.
				</p>
				

				</div>

		</section>

		<!-- <br> -->

		<section id="pt2" class="card">
			<div class="arial">
			<h3>Data Preparation</h3>
			<br>
			<h4>The first set of the label data [“environment”, “infrastructure”, “news”, “battery”, and “cost”]</h4>
			<br>
				<p>
					The data is retrieved from the file in the link below. [The Data Section] Only the records that have labels will be used in this section.
				</p>
				
				<br>
				
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/1.png">
				<div class="caption">The dataset</div>
				</div>
				
				<p>
				The labels are battery, cost, infrastructure, environment, and news. The labels are removed from the document to avoid bias. For example, “cost,” “infrastructure,” “environment,” “news,”  and “battery” will be removed from the first dataset and “positive,” “negative,” and “neutral” will be removed from the second dataset.
				</p>
				
				<br>
				
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/2.png">
				<div class="caption">The dataframe</div>
				</div>
				
				<br>

				<p>
				Then the data is splitted into the training and testing dataset. 80 percent of the data will be the training dataset. The other will be the testing dataset. The train_test_split function of the Sklearn package is used for this purpose. The function and the dataset will be shown by the pictures below. The special characters and punctuations are removed from the data. In addition, the data is also preprocessed into the lemmas using the lemmatization and stemming process. The label encoder function is used to convert the labels into the numeric type for the machine learning model. The main reason is that SVMs are designed to work with numeric labels, rather than categorical labels. This is because the optimization problem that SVMs solve involves computing distances between points in the feature space, and distances can only be computed between numeric values.	
				</p>
				<br>
				
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/3.png">
				<div class="caption">The training and testing dataset</div>
				</div>
				
				<br>
				<p>
				The total of the labeled data are 1,273 records. The training dataset has 1,018 records and the testing dataset has around 255 records. When using the supervised machine learning method like SVM, the complete dataset should not be used to train a model. Only the training set is used for the purpose; the other part of the dataset is called the testing set, which can be used to evaluate the performance of the model. It’s really important to realize that the training set and testing set are disjoint sets, so they don’t have any observation in common, this makes it possible to test our model on unseen data. In this chapter, two sets of labels will be used. The first one is the labels of “environment”, “infrastructure”, “news”, “battery”, and “cost”. The other one is the sentimental labels, which are “negative”, “neutral”, and “positive”.
				</p>
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/4.png">
				<div class="caption">The training set of documents</div>
				</div>
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/5.png">
				<div class="caption">The testing set of documents</div>
				</div>
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/6.png">
				<div class="caption">The training labels</div>
				</div>
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/7.png">
				<div class="caption">The testing labels</div>
				</div>
				<br>
				<h4>The Second set of the label data [“negative”, “neutral”, and “positive”]</h4>

				<br>
				<p>
				The total of the labeled data are 2,696 records. The training dataset has 2,156 records and the testing dataset has around 540 records. When using the supervised machine learning method like SVM, the complete dataset should not be used to train a model. Only the training set is used for the purpose; the other part of the dataset is called the testing set, which can be used to evaluate the performance of the model. It’s really important to realize that the training set and testing set are disjoint sets, so they don’t have any observation in common, this makes it possible to test our model on unseen data. The labels are the sentimental labels, which are “negative”, “neutral”, and “positive”. The label will be converted to the numeric type with the same reason as mentioned before.
				</p>
				
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/2nd_data_1.png">
				<div class="caption">The training set of documents</div>
				</div>
				
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/2nd_data_2.png">
				<div class="caption">The testing set of documents</div>
				</div>
				
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/6_1.png">
				<div class="caption">The training labels</div>
				</div>
				
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/7_1.png">
				<div class="caption">The testing labels</div>
				</div>
				
				<br>
				<p>
				For both datasets, TF-IDF and CountVectorizer are implemented. When the more outstanding method is known, several data preprocessing methods are implemented to feed data into the SVM models. For example, the documents can be stemming, lemmatization, and lemmatization together with stemming. Several kernels are used in the models. They are linear, polynomial, sigmoid, and radial basis functions. The pictures of each kernel are shown below.
				</p>
				
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/9.png">
				<div class="caption">The linear kernel SVM model</div>
				</div>
				
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/10.png">
				<div class="caption">The sigmoid kernel SVM model</div>
				</div>
				
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/11.png">
				<div class="caption">The polynomial kernel SVM model</div>
				</div>
				
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/12.png">
				<div class="caption">The RBF kernel SVM model</div>
				</div>
				
				<p>
				After some parameters are adjusted to perform hyperparameter tuning, the randomizedsearchCV are employed to find the best model among all kernels and related parameters as shown in the code below.
				</p>
				
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/image_html/13.png">
				<div class="caption">The RandomizedSearchCV</div>
				</div>
				
				<p>
				After the best model is obtained. The LinearSVC model is used to collect the top 20 important terms and plot like in the graph below. The objective is to understand the impactful terms on each label.
				</p>
				
				<br>
				<div class="img">
				<img width="600" src="image/assignment3/svm/sentiment/neg.png">
				<div class="caption">The dominant negative terms</div>
				</div>
				
				

				
				<br>
				

			</div>
		</section>
		
		<section id="pt3" class="card">
			<div class="arial">

			
			<h3>Results and Discussion</h3>
			
			<p>
			There are two parts. In the first part, the label will be the labels from the first modules, which are “news”, “infrastructure”, “environment”, “cost”, and “battery”. The second part label will be the sentimental label from the first part, which are “negative”, “neutral” and “positive”.
			</p>
			
			<br>
			<h4>The first dataset</h4>
			
			<p>
			In result and discussion, there are five important topics to investigate. There are the accuracy comparison between CountVectorizer and TF-IDF, the comparison between using lemmatization, stemming and lemmatization together with stemming, the performance of each kernels, the impact of cost on the models, and impactful words on the SVM models.
			</p>
			
			<br>
			<p>1. The accuracy comparison between CountVectorizer and TF-IDF</p>
			<br>
			
			<p>
			Both bag-of-words models (BOWs) have a max feature equal to 3000 terms. The other parameters are the same. The degree of the polynomial SVM model is set to two. All costs in each model are set to one. Lemmatization is used to transform tokens into lemmas.
			</p>
			
			<br>
			<table class="center">
			<caption>The accuracy of the models based on the bag-of-words method</caption>
			  <tr>
				<th>Model</th>
				<th>CountVectorizer (%)</th>
				<th>TF-IDF (%)</th>
			  </tr>
			  <tr>
				<td>Linear</td>
				<td>69.69</td>
				<td>75.20</td>
			  </tr>
			  <tr>
				<td>Polynomial Degree 2</td>
				<td>38.97</td>
				<td>73.23</td>
			  </tr>
			  <tr>
				<td>Sigmoid</td>
				<td>69.69</td>
				<td>76.40</td>
			  </tr>
			  <tr>
				<td>RBF</td>
				<td>66.92</td>
				<td>77.17</td>
			  </tr>
			</table>
			<br>
			
			<p>
			According to the above table, the models created from TF-IDF outperform the models created from CountVectorizer. The main reason is that TF-IDF will scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus, whereas the CountVectorizer considers only the occurrences of tokens in each document. Therefore, in the further analysis in this chapter, TF-IDF will be used as the bag-of-words model.
			</p>
			
			<br>
			<p>2. The number of max_features</p>
			<br>
			
			<p>
			In this dataset, if the max_features is not set, the total terms will be around 4,308 words. However, the excessive number of words may not be good with the models because the terms can cause the models to be too complex and degrade their accuracy. The picture below is the base TF-IDF. The number of max features will be varied. The RBF SVM model will be used to verify appropriate terms for the models.
			</p>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image_html/14.png">
			<div class="caption">The TF-IDF base function</div>
			</div>
			<br>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image_html/10.png">
			<div class="caption">The sigmoid kernel SVM</div>
			</div>
			<br>
			
			<br>
			<table class="center">
			<caption>The accuracy of the models vs max_features</caption>
			  <tr>
				<th>Model</th>
				<th>Accuracy (%)</th>
			  </tr>
			  <tr>
				<td>2000</td>
				<td>76.77</td>

			  </tr>
			  <tr>
				<td>3000</td>
				<td>77.16</td>
			  </tr>
			  <tr>
				<td>4000</td>
				<td>76.00</td>

			  </tr>

			</table>
			<br>
			
			<p>
			According to the above table, the max_features at 3000 can achieve the best accuracy. Too low max_features can reduce the accuracy of the models because of the underfitting models. In the same way, too high max features can make the models complicated and obtain poor accuracy.  Therefore, in the further analysis in this chapter, the max_features at 3000  will be used as the bag-of-words parameter.
			</p>
			
			<br>
			
			<br>
			<p>3. Stemming vs Lemmatization</p>
			<br>
			
			<p>The dataset is transformed into lemmas by using stemming, lemmatization, stemming together with lemmatization. All formats will be compared using the several kernels SVM models as mentioned in the data preparation part. The result will be shown in the table below.</p>

			<br>
			<table class="center">
			<caption>Stemming vs Lemmatization</caption>
			  <tr>
				<th>Model</th>
				<th>Stemming (%)</th>
				<th>Lemmatization (%)</th>
				<th>Stemming and Lemmatization (%)</th>
			  </tr>
			  <tr>
				<td>Linear</td>
				<td>75.60</td>
				<td>75.20</td>
				<td>75.60</td>
			  </tr>
			  <tr>
				<td>Polynomial Degree 2</td>
				<td>74.80</td>
				<td>73.60</td>
				<td>73.22</td>
			  </tr>
			  <tr>
				<td>Sigmoid</td>
				<td>74.40</td>
				<td>76.40</td>
				<td>75.60</td>
			  </tr>
			  <tr>
				<td>RBF</td>
				<td>76.37</td>
				<td>77.16</td>
				<td>76.37</td>
			  </tr>
			</table>
			<br>
			
			<p>According to the table above, the lemmatization and the stemming performance is very close in all kernels. However, the way that stemming converts tokens into lemmas make the terms meaningless. For example, “busy” will be converted to “busi”. On the contrary, lemmatization converts the terms to lemmas based on their part of speech, which performs better. The models tend to perform the same as the stemming and lemmatization when stemming and lemmatization are implemented together. Therefore, in the further analysis in this chapter, the lemmatization will be used to convert terms to lemmas because of the highest accuracy in the RBF kernel.</p>
			
			<br>
			<p>4. Kernel and cost function</p>
			<br>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image_html/cost.png">
			<div class="caption">The sigmoid kernel SVM</div>
			</div>
			<br>
			
			<p>The equation in the picture above is the cost function of the SVM model. There is a trade-off between fitting the model well on training dataset and the complexity of the model that may lead to overfitting, which can be adjusted by tweaking the value of λ or C. Both λ and C prioritize how much we care about optimizing fit terms and regularized terms. Placing at different places of cost function, C actually plays a role similar to 1/λ. With a very large value of C (similar to no regularization), this large margin classifier will be very sensitive to outliers as in the left picture below. Large C does not allow some data points to stay within the margin. On the other hand, C also plays a role to adjust the width of margin which enables margin violation. When C is small, the model allows some misclassified data points within the margin as in the right picture below. Therefore, the appropriate C has a large impact on the model accuracy.</p>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image_html/largemargin.png">
			<div class="caption">The sigmoid kernel SVM</div>
			</div>
			<br>
			
			<p>Regarding kernels, some datasets are non-linear separable data like in the picture below. The basic idea is, when a dataset is inseparable in the current dimensions, add another dimension. This way the data will be separable. Several types of kernels will be implemented to help classify data labels; In this chapter, linear, sigmoid, radial basis function (RBF), polynomial kernels will be applied with the dataset so that the model can achieve the highest accuracy.</p>
			
			<br>
			<table class="center">
			<caption>The accuracy based on c and kernels</caption>
			  <tr>
				<th>Model</th>
				<th>c=0.1</th>
				<th>c=1.0</th>
				<th>c=10.0</th>
				<th>c=100.0</th>
			  </tr>
			  <tr>
				<td>Linear</td>
				<td>59.44</td>
				<td>75.19</td>
				<td>75.19</td>
				<td>68.50</td>
			  </tr>
			  <tr>
				<td>Polynomial Degree 2</td>
				<td>18.89</td>
				<td>73.62</td>
				<td>71.65</td>
				<td>36.61</td>
			  </tr>
			  <tr>
				<td>Sigmoid</td>
				<td>59.44</td>
				<td>76.37</td>
				<td>72.83</td>
				<td>70.47</td>
			  </tr>
			  <tr>
				<td>RBF</td>
				<td>18.90</td>
				<td>77.16</td>
				<td>76.37</td>
				<td>76.37</td>
			  </tr>
			</table>
			<br>
			
			<p>According to the table above, the suitable c-value is in the range between 1.0-10.0. Every kernel works very well. The accuracy of the models is in the range of 18.1-77.2%. The best kernel is RBF with c=1.0. Its accuracy is 77.2% and its confusion matrix is shown in the picture below. The second place is the sigmoid kernel model at c=1.0. Its accuracy is 76.4%. Another observation is that when c is too low, the models tend to underfitting. For example, in the case of c=0.01, all kernels get the poor accuracy around 18.9%</p>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image_html/5label_rbf_1.png">
			<div class="caption">RBF kernel model with c=1</div>
			</div>
			<br>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image_html/f1_score_5label.png">
			<div class="caption">RBF kernel model with c=1</div>
			</div>
			<br>
			
			<p>Regarding the confusion matrix and F1-score above, the model can classify all labels very well. This results in a high F1-score in each category. The main reason may be from the unique terms in each category. This makes the model perform so well. “News” and “Environment” is the label which the model predicts better than any other labels.</p>
			
			<br>
			<p>5. The impactful terms</p>
			<br>
			
			<p>The top 20 influential terms will be collected from the linear SVM model. The weight of the terms can be obtained from the model. The plots are shown in the picture below based on each label.</p>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image/battery.png">
			<div class="caption">Important terms of battery</div>
			</div>
			<br>
			
			<p>According to the picture above, the terms having impacts on the “battery” label are “cold,” “range,” “weather,” “long charge,” etc. They are related to EVs’ batteries. The cold weather will have an impact on the performance of the battery because it will reduce the range. Currently, EVs need time to be fully charged around 45 minutes, which is long compared to gas-powered vehicles.</p> 
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image/cost.png">
			<div class="caption">Important terms of cost</div>
			</div>
			<br>
			
			<p>According to the picture above, the terms having impacts on the “cost” label are “afford,” “price,” “expense,” etc. They are related to EVs’ cost.</p>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image/env.png">
			<div class="caption">Important terms of environment</div>
			</div>
			<br>
			
			<p>According to the picture above, the terms having impacts on the environment label are “mining,” “recycle,” “lithium,” “pollution,” etc. They are related to EVs’ battery components. Lithium is the main component in the EVs’ batteries. It is obtained from mining, which causes pollution. In addition, The EVs’ battery is hard to recycle because of the complex production and its components.</p>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image/infrastructure.png">
			<div class="caption">Important terms of infrastructure</div>
			</div>
			<br>
			
			<p>According to the picture above, the terms having impacts on the “infrastructure” label are “charge,” “network,” “charge,” “grid,” etc. All of them are related to the charging facilities and charging networks.</p>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image/news.png">
			<div class="caption">Important terms of news</div>
			</div>
			<br>
			
			<p>Regarding the picture above, the terms having impacts on the “news” label are “Tesla,” “electric,” “Ford,” “stock,” etc. All of them are related to recent EVs’ news, new EVs’ models and EVs’ manufacturers such as Tesla, Ford, and Volkswagen.</p>
			<br>
			<h4>The second dataset [Sentimental labels]</h4>
			<br>
			<p>In result and discussion, there are three sentiment labels to classify. The same analysis will be conducted on the sentiment label. There are the accuracy comparison between CountVectorizer and TF-IDF, the comparison between using lemmatization, stemming and lemmatization together with stemming, the performance of each kernels, the impact of cost on the models, and impactful words on the SVM models.</p>
			
			<br>
			<p>1.The accuracy comparison between CountVectorizer and TF-IDF</p>
			<br>
			<p>
			Both bag-of-words models (BOWs) have a max feature equal to 3000 terms. The other parameters are the same. The degree of the polynomial SVM model is set to two. All costs in each model are set to one.
			</p>
			<br>
			
			<br>
			<table class="center">
			<caption>The accuracy of the models based on the bag-of-words method</caption>
			  <tr>
				<th>Model</th>
				<th>CountVectorizer (%)</th>
				<th>TF-IDF (%)</th>
			  </tr>
			  <tr>
				<td>Linear</td>
				<td>70.87</td>
				<td>69.75</td>
			  </tr>
			  <tr>
				<td>Polynomial Degree 2</td>
				<td>48.42</td>
				<td>63.26</td>
			  </tr>
			  <tr>
				<td>Sigmoid</td>
				<td>62.34</td>
				<td>63.63</td>
			  </tr>
			  <tr>
				<td>RBF</td>
				<td>63.63</td>
				<td>68.08</td>
			  </tr>
			</table>
			<br>
			<p>
			According to the above table, the models created from TF-IDF outperform the models created from CountVectorizer except the linear kernel. In linear, the model created from TF-IDF is poorer than the models created from CountVectorizer. The main reason of outperformed TF-IDF is that TF-IDF will scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus, whereas the CountVectorizer considers only the occurrences of tokens in each document. Therefore, in the further analysis in this chapter, TF-IDF will be used as the bag-of-words model.
			</p>
			<br>
			
			<br>
			<p>2. Stemming vs Lemmatization</p>
			<br>
			
			<p>
			The dataset is transformed into lemmas by using stemming, lemmatization, stemming together with lemmatization. All formats will be compared using the several kernels SVM models as mentioned in the data preparation part. The result will be shown in the table below.
			</p>
			<br>
			<table class="center">
			<caption>Stemming vs Lemmatization</caption>
			  <tr>
				<th>Model</th>
				<th>Stemming (%)</th>
				<th>Lemmatization (%)</th>
				<th>Stemming and Lemmatization (%)</th>
			  </tr>
			  <tr>
				<td>Linear</td>
				<td>69.07</td>
				<td>68.51</td>
				<td>69.25</td>
			  </tr>
			  <tr>
				<td>Polynomial Degree 2</td>
				<td>60.37</td>
				<td>61.66</td>
				<td>63.88</td>
			  </tr>
			  <tr>
				<td>Sigmoid</td>
				<td>67.71</td>
				<td>67.59</td>
				<td>68.51</td>
			  </tr>
			  <tr>
				<td>RBF</td>
				<td>66.29</td>
				<td>64.81</td>
				<td>67.96</td>
			  </tr>
			</table>
			<br>
			
			<p>
			According to the table above, the results from lemmatization and the stemming methods are close together in most cases. However, the way that stemming converts tokens into lemmas sometimes makes the terms meaningless. For example, “busy” will be converted to “busi”. On the contrary, lemmatization converts the terms to lemmas based on their part of speech, which is easier to understand. Stemming together with lemmatization tends to outperform the other methods. Therefore, in the further analysis in this chapter, stemming and lemmatization will be used to convert terms to lemmas together.
			</p>
			
			<br>
			<p>3. Kernel and cost function</p>
			<br>
			
			<br>
			<table class="center">
			<caption>The accuracy based on c and kernels</caption>
			  <tr>
				<th>Model</th>
				<th>c=0.1</th>
				<th>c=1.0</th>
				<th>c=10.0</th>
				<th>c=100.0</th>
			  </tr>
			  <tr>
				<td>Linear</td>
				<td>59.74</td>
				<td>69.75</td>
				<td>67.16</td>
				<td>67.53</td>
			  </tr>
			  <tr>
				<td>Polynomial Degree 2</td>
				<td>34.88</td>
				<td>63.26</td>
				<td>62.34</td>
				<td>49.91</td>
			  </tr>
			  <tr>
				<td>Sigmoid</td>
				<td>58.63</td>
				<td>67.72</td>
				<td>63.63</td>
				<td>56.96</td>
			  </tr>
			  <tr>
				<td>RBF</td>
				<td>34.88</td>
				<td>68.00</td>
				<td>68.65</td>
				<td>68.65</td>
			  </tr>
			</table>
			<br>
			
			<p>
			According to the table above, the suitable c-value of each kernel is different. Some kernels work better at c=10, whereas others perform well at c=1. The accuracy of the models is in the range of 35.0-70.0%. The best kernel is linear with c=1.0. Its accuracy is 70.0% and its confusion matrix is shown in the picture below. The second place is the RBF kernel model at c=10.0. Its accuracy is 68.7%. Another observation is that when c is too low, the models tend to underfitting. For example, in the case of c=0.01, all kernels get a poor accuracy of around 35.0%. When c is too low, the penalization will be high and tend to ignore outliers. The confusion matrix of the best model is shown below. 
			</p>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image_html/sen_lin_1.png">
			<div class="caption">Linear kernel model with c=1</div>
			</div>
			<br>
			
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/image_html/f1_score_sen.png">
			<div class="caption">F1-score</div>
			</div>
			<br>
			
			<p>
			Regarding the confusion matrix above, the model predicts all labels well, which implies a good f1-score around 0.68-0.73 for all labels. Just a little portion of data is misclassified. The training set is balanced which can reduce the model bias.
			</p>
			
			<br>
			<p>4. The impactful terms</p>
			<br>
			
			<p>
			The top 20 influential terms will be collected from the linear SVM model. The weight of the terms can be obtained from the model. The plots are shown in the picture below based on each label.
			</p>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/sentiment/neg.png">
			<div class="caption">Negative</div>
			</div>
			<br>
			
			<p>
			According to the picture above, the terms having impacts on the “negative” label are “bad”, “shit”, “hell”, “problem”, “die”, etc. Some of the terms are related to EVs’ problems and express negative opinions toward EVs. 
			</p>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/sentiment/neu.png">
			<div class="caption">Neutral</div>
			</div>
			<br>
			
			<p>
			According to the picture above, the terms having impacts on the “Neutral” label are “site”, “japan”, “india”, “visual”, “mode”, etc. These terms have neither positive nor negative impacts on the matter. This can reduce the model accuracy because it is hard for the model to find a good indicator to identify this label. The terms are too broad and some of them look similar to positive terms.
			</p>
			
			<br>
			<div class="img">
			<img width="600" src="image/assignment3/svm/sentiment/pos.png">
			<div class="caption">Positive</div>
			</div>
			<br>
			
			<p>
			According to the picture above, the terms having impacts on the “Positive” label are “like”, “great”, “love”, “good”, “wish”, etc. These terms give a positive feeling towards the topic.
			</p>
			
			


			</div>
		
		
		
		</section>
		
			<section id="pt4" class="card">
			<div class="arial">

			
			<h3>Conclusion</h3>
			<br>
			<h4>The first dataset </h4>
			<p>
			SVM works very well on the first label set and fairly on the sentiment label. The accuracy of the first set of labels is around 70-80%. The best kernel is RBF with c=1. The F1-score is around 70-85% for each label. The reason behind good accuracy is that the terms in each category are very unique, so the model can work very well based on these terms. Too low c makes models underfitting and get lower accuracy. The suitable c is in the range between 1.0-10.0.
			</p>
			<br>
			<h4>The second dataset </h4>
			<p>
			On the sentiment labels, the accuracy is around 35%-70%. The best kernel is a linear kernel with c=1. The F1-score is around 68-73% for each label. The model classifies the documents well. The poorer accuracy compared to the first dataset may be from some unclear meaning and ambiguous terms which can lead to text misclassification. Too low c makes models underfitting and get lower accuracy. The suitable c is in the range between 1.0-10.0. The important terms from the model in the “neutral” label is neither good nor bad feeling and are too broad to find the unique words such as “india” and “mode”. Regarding the “positive”, the important terms are positive words such as “good,” “great,” and “love”. On the contrary, the negative important terms such as “bad” and “wrong” will express a negative feeling.
			</p>
			
			
			
				
			</div>
		</section>
		
		
		<br>
		
		<section id="pt5" class="card">
		<div class="arial">
		<h2>Reference</h2>
			<ul>
				<li>https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-iii-5dff33fa015d</li>


			</ul>
		<br>
		
		

		</div>
		</section>	
		


		
		<section id="Data" class="card">
			<b> Data </b>
			<br>
			<ul>
				<li><a href="https://o365coloradoedu-my.sharepoint.com/:x:/g/personal/tito7259_colorado_edu/ET6om4nRsF5EpE73BSFgd-gBpSIcfvcN-bBpy_Bq3pq5qw?e=tfXqqZ">The first dataset</a></li>
				<li><a href="https://o365coloradoedu-my.sharepoint.com/:x:/g/personal/tito7259_colorado_edu/ETIB29xnIEVFjK1X_nYqPn4BfDBldaf0ANXmmNyRUAy3XQ?e=IZKKkI">The second dataset</a></li>
				<li><a href="https://o365coloradoedu-my.sharepoint.com/:u:/g/personal/tito7259_colorado_edu/EUy3eBUq27dNv-c2qefYF8MB4DD-MIehvk9pQdf59T3YfA?e=va6BoZ">SVM Python file</a></li>

			
				<li><a href="">etc</a></li>

			</ul>

			<hr>

		</section>

	</main>

</body>

<!-- Sidebar-->
<div id="sidebar" class="card">
	<h3>Navigation Pane</h3>
	<!-- Navigation -->
	<ul id="main-nav">
		<li><a href="#pt1">What SVM does and how to use it to gain information</a></li>
		<li><a href="#pt2">Data Preparation</a></li>
		<li><a href="#pt3">Results and Discussion</a></li>
		<li><a href="#pt4">Conclusion</a></li>
		<li><a href="#Data">Data</a></li>
	</ul>
	<hr />
	<h3>About me</h3>
	<ul>
		<li><strong>Email:</strong> tito7259@colorado.edu</li>
	</ul>
</div>